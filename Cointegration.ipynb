{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6abc09a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "from statsmodels.tsa.vector_ar.vecm import select_coint_rank\n",
    "import datetime\n",
    "import matplotlib\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "%matplotlib notebook\n",
    "\n",
    "#If VAR matrix has complete rank, the variables are cointegrated and are an I(0)\n",
    "#If the VAR matrix has null rank, then the variables are not cointegrated.\n",
    "#If the VAR matrix has a rank in between, there is cointegration between 2 or more variables.\n",
    "\n",
    "##The Johansen test is based on the theorem of nullity + rank = rows\n",
    "##The geometric mutiplicity of Lambda = 0 as an eigenvalue is equal to the NULLITY\n",
    "##The nullspace of T is the solution to the homogeneus eq.: Ax = 0 (Av = Lambda*v when Lambda = 0)\n",
    "##The nullity of T is the dimension of the Nullspace, and it is set by the number of free variables in the solution of the equation above (the Nullspace)\n",
    "##Since the number of free variables mentioned in the previous point (nullity) is set by the number of variables (columns) - the number of equations \n",
    "#and the number of equations is equal to the independent rows (rank), then the nullity is equal to the number of columns - the rank.\n",
    "##For cointegration you will always have a square Matrix, so the nullity is going to be determined only by the number of independent rows (and not by the difference cloumns - rows as well)\n",
    "##The geometric multiplicity of an eigenvalue is the dimension of the vectors associated with it, in the case of Lambda = 0 it is the nullity\n",
    "#In the case of the other vectors you just have to create a subspace with all the eigenvectors associated with the eigenvalue an see what dimension of the subspace is.\n",
    "#In general, all the gemoetric multiplicities are gotten by the dimension of the nullity of A-lambda*I for every lambda\n",
    "#(for lambda = 0 it turns to the be the nullspace of A because A-0*I = A).\n",
    "##The algebraic  multiplicity is simply the number of times a certain lambda value appears as a root of the characteristic polynomic of A\n",
    "#The geometric multiplicity can never exeed the algebraic multiplicity.\n",
    "#If you add-up all the algebraic multiplicities of every lambda in A (including the nullity of A [geom. multiplicity of lambda = 0]) then you get the number of columns of A. \n",
    "\n",
    "##The fundament of the Johansen test is that in Algebra, every nullspace vector corresponds to a linear relationship amongst the variables\n",
    "##The number of these linear relationships is given by the size of the nullspace.\n",
    "##This contrast first orders the lambdas from highest to lowest, then (presumably assuming the same distribution for every lambda)\n",
    "#it does a significance contast with the null hypothesis that the highest lamda is equal to 0, if the hypothesis is rejected, then\n",
    "#the significance test is repeated with the next lambda. If it is accepted, we assume the rank of the matrix is 0 (if the highest lambda is 0\n",
    "#we assume the lower lambdas [the subsequent ones in the ordered succesion] will be 0 too.)\n",
    "##The normalized eigenvectors in relation to the first column give you the cointegration relationships.\n",
    "##There is a theorem that states that the sum of all the eigenvalues is equal to the trace of the Matrix, that is why there is also a Trace contrast\n",
    "#and it is because the size of the trace will give you an idea of how big the sum of the eigenvalues is and hence how likely it is that they are far from 0.\n",
    "##The maximum eigenvalue test examines whether the largest eigenvalue is zero relative to the alternative that the next largest eigenvalue is zero.\n",
    "\n",
    "\n",
    "os.getcwd()\n",
    "\n",
    "data = pd.read_csv('C:/Users/D110148/OneDrive - pzem/data/Cointegration_Test.csv', sep = \";\")\n",
    "data.index = [pd.to_datetime(i, infer_datetime_format=True) for i in data['Index']]\n",
    "data = data.iloc[:,1:]\n",
    "data.where(data == 'NaN', np.nan)\n",
    "data.interpolate(inplace=True)\n",
    "\n",
    "data_to_coint = data[[data.columns[2],data.columns[4],data.columns[5]]]\n",
    "results = coint_johansen(data_to_coint[data_to_coint.index > datetime.datetime(2021,6,23)], det_order = 0,k_ar_diff=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f72f7a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([13.53636308,  7.39114532,  5.43159294]),\n",
       " array([[18.8928, 21.1314, 25.865 ],\n",
       "        [12.2971, 14.2639, 18.52  ],\n",
       "        [ 2.7055,  3.8415,  6.6349]]))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Max eigenvalue contrast\n",
    "\n",
    "results.max_eig_stat, results.max_eig_stat_crit_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f0133bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([26.35910134, 12.82273826,  5.43159294]),\n",
       " array([[27.0669, 29.7961, 35.4628],\n",
       "        [13.4294, 15.4943, 19.9349],\n",
       "        [ 2.7055,  3.8415,  6.6349]]))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trace contrast:\n",
    "\n",
    "results.trace_stat, results.trace_stat_crit_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "77e892d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rank according to the contrast:\n",
    "\n",
    "results2=select_coint_rank(data_to_coint[data_to_coint.index > datetime.datetime(2021,6,23)], det_order = 0,k_ar_diff=2)\n",
    "\n",
    "results2.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01597aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04594633, 0.01747393, 0.00233587])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Eigenvalues\n",
    "\n",
    "results.eig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a9a4724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying random experiment\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "random.seed(6)\n",
    "\n",
    "yields1 = [random.normalvariate(0,0.012) for i in range(365)]\n",
    "\n",
    "process1 = []\n",
    "\n",
    "P0 = 15\n",
    "\n",
    "process1.append(P0)\n",
    "\n",
    "for i in yields1:\n",
    "    P0 = P0*(1+i)\n",
    "    process1.append(P0)\n",
    "    \n",
    "process2 = [i*0.35 for i in process1]\n",
    "\n",
    "yields3 = [random.normalvariate(0,0.014) for i in range(365)]\n",
    "\n",
    "process3 = []\n",
    "\n",
    "P0 = 20\n",
    "\n",
    "process3.append(P0)\n",
    "\n",
    "for i in yields3:\n",
    "    P0 = P0*(1+i)\n",
    "    process3.append(P0)\n",
    "    \n",
    "    \n",
    "randomData = pd.DataFrame({'process_1':process1,'process_2':process2,'process_3':process3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c4e05831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results4 = select_coint_rank(randomData,det_order=0,k_ar_diff=2)\n",
    "\n",
    "#The rank of the error correction model matrix is (according to the significance Test):\n",
    "\n",
    "results4.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "fcf8d368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([36.12356219,  4.71305756,  0.8677315 ]),\n",
       " array([[18.8928, 21.1314, 25.865 ],\n",
       "        [12.2971, 14.2639, 18.52  ],\n",
       "        [ 2.7055,  3.8415,  6.6349]]))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results5 = coint_johansen(randomData, det_order=0, k_ar_diff=2)\n",
    "\n",
    "#Significance test:\n",
    "\n",
    "results5.max_eig_stat, results5.max_eig_stat_crit_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2b6d414c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.93572358e+02,  3.48978776e+00,  3.95428224e+00],\n",
       "       [-2.55304849e+03, -1.36999180e+01, -1.14832792e+01],\n",
       "       [ 1.97616097e-03,  1.56242395e-01, -4.57127043e-01]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The eigenvectors are:\n",
    "\n",
    "results5.evec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "69d44386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00000000e+00, -2.85712563e+00,  2.21152876e-06])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since the rank is one, we only take the first eigenvector, because there is only 1 cointegration relationship\n",
    "#We normalize the eigenvector with regard to the first variable:\n",
    "\n",
    "vector = results5.evec[:,0]/results5.evec[0][0]\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "488331c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3500021102931373"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#So the coefficient we are interested in is -2.85712563e+00, because there is only cointegration between the first two variables\n",
    "#Let's check that that the inverse of the coefficient is 0.35, as we defined process2 = process1*0.35:\n",
    "\n",
    "1/vector[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d6f9c0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.85714286, 0.        ])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now let's check that the coefficient -2.85712563e+00 is also achievable through a linear regression:\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LinearReg = LinearRegression()\n",
    "\n",
    "LinearReg.fit(randomData.iloc[:,1:] , randomData.iloc[:,0])\n",
    "\n",
    "LinearReg.coef_\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
